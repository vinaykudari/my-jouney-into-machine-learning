{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"American sign language classifier from scratch\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [classifier, scratch, vision]\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18436, 785), (7901, 785))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/code/datasets/mnist_sign/sign_mnist_train.csv')\n",
    "classes = range(24)\n",
    "df = df[df.label.isin(classes)]\n",
    "train_df = df.sample(frac=0.7, random_state=100)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    return tensor(df.iloc[:, 0].values).to('cuda')\n",
    "\n",
    "def get_image_tensors(df):\n",
    "    return torch.stack([tensor(image_array)/255. for image_array in df.iloc[:, 1:].values]).to('cuda')\n",
    "\n",
    "def get_dataset(df):\n",
    "    return zip(get_image_tensors(df), get_labels(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = get_dataset(df)\n",
    "\n",
    "for image_tensor, label in list(dataset)[:2]:\n",
    "    print(label)\n",
    "    show_image(torch.reshape(image_tensor, (28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_weights(rows, cols):\n",
    "    return torch.randn(rows, cols).requires_grad_().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 24]), torch.Size([1, 24]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = get_random_weights(28*28, len(classes))\n",
    "bias = get_random_weights(1, len(classes))\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([18436, 784]), torch.Size([784, 24]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_tensors = get_image_tensors(train_df)\n",
    "image_tensors.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(image_tensors, weights, bias):\n",
    "    return image_tensors@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18436, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = get_predictions(image_tensors, weights, bias)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check initial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0558)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_tensors, test_labels = get_image_tensors(test_df), get_labels(test_df)\n",
    "test_preds = get_predictions(test_image_tensors, weights, bias)\n",
    "pred_classes = torch.argmax(test_preds, dim=1)\n",
    "\n",
    "# This will select the class value based on index of pred_classes\n",
    "preds = tensor(classes).gather(0, pred_classes)\n",
    "(preds == test_labels).float().mean() \n",
    "\n",
    "# Random weights are ~26% accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  3,  2, 14,  5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = get_labels(train_df)\n",
    "# get each label class\n",
    "target_classes = tensor([classes.index(c) for c in labels])\n",
    "target_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6.3239e-17, 8.2544e-10, 2.2733e-07, 3.7576e-15, 4.5148e-20, 1.1652e-11,\n",
       "         4.1126e-16, 7.5506e-11, 3.5858e-05, 3.4664e-14, 1.2419e-25, 2.7958e-11,\n",
       "         1.3270e-28, 4.7249e-15, 1.7871e-15, 3.1533e-34, 1.0527e-21, 9.9996e-01,\n",
       "         3.2225e-10, 1.4737e-17, 6.0123e-15, 4.5272e-10, 1.8749e-19, 8.8592e-15],\n",
       "        grad_fn=<SelectBackward>),\n",
       " tensor([6.3239e-17, 8.2545e-10, 2.2733e-07, 3.7576e-15, 4.5148e-20, 1.1652e-11,\n",
       "         4.1126e-16, 7.5506e-11, 3.5858e-05, 3.4664e-14, 1.2419e-25, 2.7958e-11,\n",
       "         1.3270e-28, 4.7249e-15, 1.7871e-15, 3.1533e-34, 1.0527e-21, 9.9996e-01,\n",
       "         3.2225e-10, 1.4737e-17, 6.0123e-15, 4.5272e-10, 1.8749e-19, 8.8592e-15],\n",
       "        grad_fn=<SelectBackward>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax function turns the predictions into probabilities and amplifies the predictions \n",
    "def softmax(predictions):\n",
    "    return torch.exp(predictions)/torch.exp(predictions).sum(dim=1, keepdim=True)\n",
    "# pytorch equivalent\n",
    "activations_py = torch.softmax(predictions, dim=1)\n",
    "activations = softmax(predictions)\n",
    "\n",
    "activations[0], activations_py[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0548, grad_fn=<MeanBackward0>),\n",
       " tensor(0.0548, grad_fn=<NegBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of corresponding activations based on the target class\n",
    "loss = activations[range(len(target_classes)), target_classes].mean()\n",
    "# pytorch equivalent \n",
    "loss_py = -F.nll_loss(activations, target_classes)\n",
    "\n",
    "loss, loss_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as softmax function turns predictions into probabilities, each activation is bounded between (0, 1) hence our model considers 0.900 and 0.999 as the same but the second prediction is 100 times more confident hence we use log to amplify the domain to (-inf, inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(inf, grad_fn=<NegBackward>),\n",
       " tensor(31.9168, grad_fn=<NllLossBackward>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax + log + negative_loss_likelyhood = cross_entropy_loss: this can be used for classification problems\n",
    "def cross_entropy_loss(predictions, target_classes): \n",
    "    activations = softmax(predictions)\n",
    "    activations_log = torch.log(activations)\n",
    "    loss = activations_log[range(len(target_classes)), target_classes].mean()\n",
    "    return -loss\n",
    "# pytorch equivalent\n",
    "cross_entropy_loss_py = F.cross_entropy(predictions, target_classes)\n",
    "\n",
    "cross_entropy_loss(predictions, target_classes), cross_entropy_loss_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dl, weights, bias, learning_rate):\n",
    "    for x, y in dl:\n",
    "        preds = get_predictions(x, weights, bias)\n",
    "        loss = cross_entropy_loss(preds, tensor([classes.index(item) for item in y]))\n",
    "        loss.backward()\n",
    "        weights.data = weights.data - weights.grad*learning_rate\n",
    "        bias.data -= bias.grad*learning_rate\n",
    "        weights.grad.zero_()\n",
    "        bias.grad.zero_()\n",
    "    print(f'loss={loss}')\n",
    "    return weights, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=nan\n",
      "loss=nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    dl = DataLoader(get_dataset(train_df), batch_size=512)\n",
    "    weights, bias = train_epoch(dl, weights, bias, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_tensors, test_labels = get_image_tensors(test_df), get_labels(test_df)\n",
    "test_preds = get_predictions(test_image_tensors, weights, bias)\n",
    "pred_classes = torch.argmax(test_preds, dim=1)\n",
    "\n",
    "# This will select the class value based on index of pred_classes\n",
    "preds = tensor(classes).gather(0, pred_classes)\n",
    "(preds == test_labels).float().mean() \n",
    "\n",
    "# Random weights are ~26% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[0]].values).float().mean(0)[1:],\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(weights[:, 0], (28, 28)),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[0]].values[0][1:]),\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[1]].values).float().mean(0)[1:],\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(weights[:, 1], (28, 28)),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[1]].values[0][1:]),\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[2]].values).float().mean(0)[1:],\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(weights[:, 2], (28, 28)),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[2]].values[0][1:]),\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[3]].values).float().mean(0)[1:],\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(weights[:, 3], (28, 28)),\n",
    "    cmap='gray'\n",
    ")\n",
    "show_image(\n",
    "    torch.reshape(\n",
    "        tensor(df[df.label == classes[3]].values[0][1:]),\n",
    "        (28, 28)\n",
    "    ),\n",
    "    cmap='gray'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(tensor(df[df.label == classes[3]].values).float().mean(0)[1:], weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(tensor(df[df.label == classes[2]].values).float().mean(0)[1:], weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(tensor(df[df.label == classes[1]].values).float().mean(0)[1:], weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_predictions(tensor(df[df.label == classes[0]].values).float().mean(0)[1:], weights, bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
